---
title: "Практическая работа 006"
author: "dolgov18012005@yandex.ru"
format: 
  md:
    output-file: README.md
---

## Цель работы

1.  Закрепить навыки исследования данных журнала Windows Active Directory
2.  Изучить структуру журнала системы Windows Active Directory
3.  Закрепить практические навыки использования языка программирования R для обработки данных
4.  Закрепить знания основных функций обработки данных экосистемы tidyverse языка R


## Исходные данные

1.  Программное обеспечение Manjaro
2.  Rstudio Desktop
3.  Интерпретатор языка R 4.5.1

## Задание

Используя программный пакет dplyr языка программирования R провести анализ журналов и ответить на вопросы.

## Ход работы

1.  Подготовка данных  \
    1.1. Импортируйте данные в R. Это можно выполнить с помощью jsonlite::stream_in(file()) . Датасет находится по адресу https://storage.yandexcloud.net/iamcth-data/dataset.tar.gz \
    1.2. Привести датасеты в вид “аккуратных данных”, преобразовать типы столбцов в соответствии с типом данных  \
    1.3. Просмотрите общую структуру данных с помощью функции glimpse()  

2.  Анализ  \
    2.1. Раскройте датафрейм избавившись от вложенных датафреймов. Для обнаружения таких можно использовать функцию dplyr::glimpse() , а для раскрытия вложенности – tidyr::unnest() . Обратите внимание, что при раскрытии теряются внешние названия колонок – это можно предотвратить если использовать параметр tidyr::unnest(..., names_sep = ).\
    2.2. Минимизируйте количество колонок в датафрейме – уберите колоки с единственным значением параметра. \
    2.3. Какое количество хостов представлено в данном датасете? \
    2.4. Подготовьте датафрейм с расшифровкой Windows Event_ID, приведите типы данных к типу их значений. \
    2.5. Есть ли в логе события с высоким и средним уровнем значимости? Сколько их?\ 



### Шаг 1

#### Импортируем данные


```{r}
library(jsonlite)
library(tidyverse)

untar(tarfile = "dataset.tar.gz", exdir = "./")
data <-jsonlite::stream_in(file("caldera_attack_evals_round1_day1_2019-10-20201108.json"), verbose = FALSE)
```

#### Приведем датасет в аккуратный вид

```{r}
data <- data %>%
  rename(., 
         metadata = `@metadata`, 
         timestamp = `@timestamp`
  )
```

#### Просмотрим общую структуру данных с помощью функции glimpse()  

```{r}
glimpse(data)
```

### Шаг 2

#### Раскроем датасет и избавимся от вложенных датафреймов


```{r}
data_clean <- data %>%
  unnest(
    cols = c(metadata, event, log, host, agent, ecs),
    names_sep = "_",
    keep_empty = TRUE
  ) %>%
  unnest(
    cols = winlog,
    names_sep = "_",
    keep_empty = TRUE
  ) %>%
  unnest(
    cols = c(winlog_event_data, winlog_user, winlog_user_data, winlog_process),
    names_sep = "_",
    keep_empty = TRUE
  ) %>%
  mutate(., 
        timestamp = as.POSIXct(timestamp, format = "%Y-%m-%dT%H:%M:%OSZ", tz = "UTC"),
        event_created = as.POSIXct(event_created, format = "%Y-%m-%dT%H:%M:%OSZ", tz = "UTC")
  )
```

#### Посмотрим струткуру датасета с помощью

```{r}
glimpse(data_clean)
```

#### Уберем колонки с единственным значением параметра

```{r}
data_short <- data_clean %>%
  select(where(~ n_distinct(.x) > 1))

glimpse(data_short)
```

#### Найдем сколько хостов в данном датасете

```{r}
 data_short %>%
  pull(winlog_computer_name) %>%
  na.omit() %>%
  unique() %>%
  length()
```

#### Подготовим датафрейм с расшифровкой Windows Event_ID, приведем типы данных к типу их значений.

```{r}
library(xml2)
library(rvest)
webpage_url <- "https://learn.microsoft.com/en-us/windows-server/identity/ad-ds/plan/appendix-l--events-to-monitor"
webpage <- xml2::read_html(webpage_url)
event_df <- rvest::html_table(webpage)[[1]]

clean_event_df <- event_df %>%
  rename(., 
         Current_Windows_Event_ID=1,
         Legacy_Windows_Event_ID=2,
         Potential_Criticality=3,
         Event_Summary=4
         ) %>%
  mutate(.,
         Current_Windows_Event_ID = as.integer(Current_Windows_Event_ID),
         Legacy_Windows_Event_ID = as.integer(Legacy_Windows_Event_ID)
         )

glimpse(clean_event_df)
```

#### Найдем в логе события (если они есть) с высоким и средним уровнем значимости и посчитаем их

```{r}
high_med_risk = data_short %>%
  left_join(., clean_event_df, by=c("event_code"="Current_Windows_Event_ID")) %>%
  filter(., Potential_Criticality == "High" | Potential_Criticality == "Medium" | Potential_Criticality == "Medium to High")

high_med_risk
```

Как можно заметить таких событий нет

### Итог

Отчёт написан и оформлен
